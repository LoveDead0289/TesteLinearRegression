{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eee5d139",
   "metadata": {},
   "source": [
    "# ü§ñ Modelo de Machine Learning - Predi√ß√£o de Pre√ßos\n",
    "\n",
    "**Autor:** Marcos Paulo Roriz Lima Reis  \n",
    "**RA:** 22007534  \n",
    "**Email:** marcos.paulor@sempreceub.com  \n",
    "**Curso:** Engenharia da Computa√ß√£o - UniCEUB  \n",
    "\n",
    "## üéØ Objetivos\n",
    "- Implementar modelos de regress√£o para predi√ß√£o de pre√ßos\n",
    "- Comparar performance de diferentes algoritmos\n",
    "- Avaliar qualidade das predi√ß√µes\n",
    "- Fazer predi√ß√µes para novos im√≥veis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91428c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa√ß√£o das bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Configura√ß√£o dos gr√°ficos\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"‚úÖ Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb391bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento dos dados tratados\n",
    "data_path = Path('../data/imoveis_rurais_tratados.csv')\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"üìä Dataset carregado com {len(df)} registros\")\n",
    "print(f\"üìè Dimens√µes: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15bc768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepara√ß√£o dos dados para modelagem\n",
    "print(\"üîß Preparando dados para modelagem...\")\n",
    "\n",
    "# Selecionar features num√©ricas\n",
    "numeric_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if 'preco' in numeric_features:\n",
    "    numeric_features.remove('preco')  # Remover target\n",
    "\n",
    "print(f\"üìã Features num√©ricas dispon√≠veis: {numeric_features}\")\n",
    "\n",
    "# Verificar dados ausentes\n",
    "missing_data = df[numeric_features + ['preco']].isnull().sum()\n",
    "print(f\"\\nüîç Dados ausentes:\")\n",
    "print(missing_data[missing_data > 0])\n",
    "\n",
    "# Remover registros com dados ausentes\n",
    "df_model = df[numeric_features + ['preco']].dropna()\n",
    "print(f\"\\nüìä Dataset para modelagem: {len(df_model)} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c96892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir vari√°veis X e y\n",
    "X = df_model[numeric_features]\n",
    "y = df_model['preco']\n",
    "\n",
    "print(f\"üìã Features (X): {list(X.columns)}\")\n",
    "print(f\"üéØ Target (y): preco\")\n",
    "print(f\"üìä Shape X: {X.shape}\")\n",
    "print(f\"üìä Shape y: {y.shape}\")\n",
    "\n",
    "# Estat√≠sticas das features\n",
    "print(\"\\nüìà Estat√≠sticas das Features:\")\n",
    "print(X.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9c5f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divis√£o em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"üìä Conjunto de treino: {X_train.shape[0]} registros\")\n",
    "print(f\"üìä Conjunto de teste: {X_test.shape[0]} registros\")\n",
    "print(f\"üìä Propor√ß√£o treino/teste: {X_train.shape[0]/X_test.shape[0]:.1f}:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939145f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliza√ß√£o dos dados\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"‚öñÔ∏è Dados normalizados com StandardScaler\")\n",
    "print(f\"üìä M√©dia das features (treino): {np.mean(X_train_scaled, axis=0)}\")\n",
    "print(f\"üìä Desvio padr√£o das features (treino): {np.std(X_train_scaled, axis=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0469374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 1: Regress√£o Linear\n",
    "print(\"ü§ñ Treinando Modelo de Regress√£o Linear...\")\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predi√ß√µes\n",
    "y_pred_lr_train = lr_model.predict(X_train_scaled)\n",
    "y_pred_lr_test = lr_model.predict(X_test_scaled)\n",
    "\n",
    "# M√©tricas\n",
    "lr_r2_train = r2_score(y_train, y_pred_lr_train)\n",
    "lr_r2_test = r2_score(y_test, y_pred_lr_test)\n",
    "lr_rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_lr_train))\n",
    "lr_rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_lr_test))\n",
    "lr_mae_test = mean_absolute_error(y_test, y_pred_lr_test)\n",
    "\n",
    "print(f\"\\nüìà Regress√£o Linear - Resultados:\")\n",
    "print(f\"   R¬≤ Treino: {lr_r2_train:.4f}\")\n",
    "print(f\"   R¬≤ Teste: {lr_r2_test:.4f}\")\n",
    "print(f\"   RMSE Treino: R$ {lr_rmse_train:,.2f}\")\n",
    "print(f\"   RMSE Teste: R$ {lr_rmse_test:,.2f}\")\n",
    "print(f\"   MAE Teste: R$ {lr_mae_test:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235341a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 2: Random Forest\n",
    "print(\"üå≤ Treinando Modelo Random Forest...\")\n",
    "\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100, \n",
    "    random_state=42,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5\n",
    ")\n",
    "rf_model.fit(X_train, y_train)  # Random Forest n√£o precisa de normaliza√ß√£o\n",
    "\n",
    "# Predi√ß√µes\n",
    "y_pred_rf_train = rf_model.predict(X_train)\n",
    "y_pred_rf_test = rf_model.predict(X_test)\n",
    "\n",
    "# M√©tricas\n",
    "rf_r2_train = r2_score(y_train, y_pred_rf_train)\n",
    "rf_r2_test = r2_score(y_test, y_pred_rf_test)\n",
    "rf_rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_rf_train))\n",
    "rf_rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_rf_test))\n",
    "rf_mae_test = mean_absolute_error(y_test, y_pred_rf_test)\n",
    "\n",
    "print(f\"\\nüå≤ Random Forest - Resultados:\")\n",
    "print(f\"   R¬≤ Treino: {rf_r2_train:.4f}\")\n",
    "print(f\"   R¬≤ Teste: {rf_r2_test:.4f}\")\n",
    "print(f\"   RMSE Treino: R$ {rf_rmse_train:,.2f}\")\n",
    "print(f\"   RMSE Teste: R$ {rf_rmse_test:,.2f}\")\n",
    "print(f\"   MAE Teste: R$ {rf_mae_test:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4aac6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compara√ß√£o dos modelos\n",
    "comparison_data = {\n",
    "    'Modelo': ['Regress√£o Linear', 'Random Forest'],\n",
    "    'R¬≤ Treino': [lr_r2_train, rf_r2_train],\n",
    "    'R¬≤ Teste': [lr_r2_test, rf_r2_test],\n",
    "    'RMSE Teste': [lr_rmse_test, rf_rmse_test],\n",
    "    'MAE Teste': [lr_mae_test, rf_mae_test]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"üèÜ Compara√ß√£o dos Modelos:\")\n",
    "print(\"=\" * 60)\n",
    "print(comparison_df.to_string(index=False, float_format='%.4f'))\n",
    "\n",
    "# Identificar melhor modelo\n",
    "best_model_idx = comparison_df['R¬≤ Teste'].idxmax()\n",
    "best_model_name = comparison_df.loc[best_model_idx, 'Modelo']\n",
    "print(f\"\\nü•á Melhor modelo: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889fdde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza√ß√£o das predi√ß√µes\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Regress√£o Linear\n",
    "axes[0].scatter(y_test, y_pred_lr_test, alpha=0.6, color='blue')\n",
    "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[0].set_xlabel('Pre√ßo Real (R$)')\n",
    "axes[0].set_ylabel('Pre√ßo Predito (R$)')\n",
    "axes[0].set_title(f'üìà Regress√£o Linear\\nR¬≤ = {lr_r2_test:.3f}')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Random Forest\n",
    "axes[1].scatter(y_test, y_pred_rf_test, alpha=0.6, color='green')\n",
    "axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[1].set_xlabel('Pre√ßo Real (R$)')\n",
    "axes[1].set_ylabel('Pre√ßo Predito (R$)')\n",
    "axes[1].set_title(f'üå≤ Random Forest\\nR¬≤ = {rf_r2_test:.3f}')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db240eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import√¢ncia das features (Random Forest)\n",
    "if len(X.columns) > 1:\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Import√¢ncia': rf_model.feature_importances_\n",
    "    }).sort_values('Import√¢ncia', ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=feature_importance, x='Import√¢ncia', y='Feature', palette='viridis')\n",
    "    plt.title('üå≤ Import√¢ncia das Features - Random Forest')\n",
    "    plt.xlabel('Import√¢ncia')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"üìä Ranking de Import√¢ncia das Features:\")\n",
    "    for idx, row in feature_importance.iterrows():\n",
    "        print(f\"   {row['Feature']}: {row['Import√¢ncia']:.4f}\")\n",
    "else:\n",
    "    print(\"üìä Apenas uma feature dispon√≠vel para modelagem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84799968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise de res√≠duos\n",
    "residuals_lr = y_test - y_pred_lr_test\n",
    "residuals_rf = y_test - y_pred_rf_test\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Res√≠duos vs Predi√ß√µes - Linear\n",
    "axes[0,0].scatter(y_pred_lr_test, residuals_lr, alpha=0.6, color='blue')\n",
    "axes[0,0].axhline(y=0, color='r', linestyle='--')\n",
    "axes[0,0].set_xlabel('Predi√ß√µes')\n",
    "axes[0,0].set_ylabel('Res√≠duos')\n",
    "axes[0,0].set_title('üìà Res√≠duos - Regress√£o Linear')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Histograma dos res√≠duos - Linear\n",
    "axes[0,1].hist(residuals_lr, bins=20, alpha=0.7, color='blue', edgecolor='black')\n",
    "axes[0,1].set_xlabel('Res√≠duos')\n",
    "axes[0,1].set_ylabel('Frequ√™ncia')\n",
    "axes[0,1].set_title('üìä Distribui√ß√£o dos Res√≠duos - Linear')\n",
    "\n",
    "# Res√≠duos vs Predi√ß√µes - Random Forest\n",
    "axes[1,0].scatter(y_pred_rf_test, residuals_rf, alpha=0.6, color='green')\n",
    "axes[1,0].axhline(y=0, color='r', linestyle='--')\n",
    "axes[1,0].set_xlabel('Predi√ß√µes')\n",
    "axes[1,0].set_ylabel('Res√≠duos')\n",
    "axes[1,0].set_title('üå≤ Res√≠duos - Random Forest')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Histograma dos res√≠duos - Random Forest\n",
    "axes[1,1].hist(residuals_rf, bins=20, alpha=0.7, color='green', edgecolor='black')\n",
    "axes[1,1].set_xlabel('Res√≠duos')\n",
    "axes[1,1].set_ylabel('Frequ√™ncia')\n",
    "axes[1,1].set_title('üìä Distribui√ß√£o dos Res√≠duos - RF')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45691375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para fazer predi√ß√µes\n",
    "def predict_price(model, scaler, **kwargs):\n",
    "    \"\"\"Fun√ß√£o para predizer pre√ßo de um im√≥vel\"\"\"\n",
    "    # Criar DataFrame com as features\n",
    "    input_data = pd.DataFrame([kwargs])\n",
    "    \n",
    "    # Garantir que todas as features est√£o presentes\n",
    "    for col in X.columns:\n",
    "        if col not in input_data.columns:\n",
    "            input_data[col] = 0  # Valor padr√£o\n",
    "    \n",
    "    # Reordenar colunas\n",
    "    input_data = input_data[X.columns]\n",
    "    \n",
    "    # Fazer predi√ß√£o\n",
    "    if model == rf_model:\n",
    "        prediction = model.predict(input_data)[0]\n",
    "    else:  # Linear Regression\n",
    "        input_scaled = scaler.transform(input_data)\n",
    "        prediction = model.predict(input_scaled)[0]\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "# Exemplo de predi√ß√£o\n",
    "print(\"üîÆ Exemplo de Predi√ß√£o:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Usar valores m√©dios das features como exemplo\n",
    "example_features = {}\n",
    "for col in X.columns:\n",
    "    example_features[col] = X[col].mean()\n",
    "\n",
    "print(f\"üìã Features do exemplo:\")\n",
    "for feature, value in example_features.items():\n",
    "    print(f\"   {feature}: {value:.2f}\")\n",
    "\n",
    "# Predi√ß√µes\n",
    "pred_lr = predict_price(lr_model, scaler, **example_features)\n",
    "pred_rf = predict_price(rf_model, scaler, **example_features)\n",
    "\n",
    "print(f\"\\nüí∞ Predi√ß√µes de Pre√ßo:\")\n",
    "print(f\"   Regress√£o Linear: R$ {pred_lr:,.2f}\")\n",
    "print(f\"   Random Forest: R$ {pred_rf:,.2f}\")\n",
    "print(f\"   Pre√ßo m√©dio real: R$ {y.mean():,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81f61d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valida√ß√£o cruzada\n",
    "print(\"üîÑ Realizando Valida√ß√£o Cruzada...\")\n",
    "\n",
    "# Linear Regression\n",
    "cv_scores_lr = cross_val_score(lr_model, X_train_scaled, y_train, cv=5, scoring='r2')\n",
    "print(f\"\\nüìà Regress√£o Linear - CV:\")\n",
    "print(f\"   R¬≤ m√©dio: {cv_scores_lr.mean():.4f} (¬±{cv_scores_lr.std()*2:.4f})\")\n",
    "print(f\"   R¬≤ por fold: {cv_scores_lr}\")\n",
    "\n",
    "# Random Forest\n",
    "cv_scores_rf = cross_val_score(rf_model, X_train, y_train, cv=5, scoring='r2')\n",
    "print(f\"\\nüå≤ Random Forest - CV:\")\n",
    "print(f\"   R¬≤ m√©dio: {cv_scores_rf.mean():.4f} (¬±{cv_scores_rf.std()*2:.4f})\")\n",
    "print(f\"   R¬≤ por fold: {cv_scores_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e2dc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo final\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéØ RESUMO FINAL DOS MODELOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüìä Dataset:\")\n",
    "print(f\"   Total de registros: {len(df_model)}\")\n",
    "print(f\"   Features utilizadas: {len(X.columns)}\")\n",
    "print(f\"   Treino/Teste: {len(X_train)}/{len(X_test)}\")\n",
    "\n",
    "print(f\"\\nüèÜ Melhor Modelo: {best_model_name}\")\n",
    "if best_model_name == 'Random Forest':\n",
    "    print(f\"   R¬≤ Teste: {rf_r2_test:.4f}\")\n",
    "    print(f\"   RMSE: R$ {rf_rmse_test:,.2f}\")\n",
    "    print(f\"   MAE: R$ {rf_mae_test:,.2f}\")\n",
    "else:\n",
    "    print(f\"   R¬≤ Teste: {lr_r2_test:.4f}\")\n",
    "    print(f\"   RMSE: R$ {lr_rmse_test:,.2f}\")\n",
    "    print(f\"   MAE: R$ {lr_mae_test:,.2f}\")\n",
    "\n",
    "print(f\"\\nüí° Interpreta√ß√£o:\")\n",
    "if max(rf_r2_test, lr_r2_test) > 0.7:\n",
    "    print(\"   ‚úÖ Modelo com boa capacidade preditiva\")\n",
    "elif max(rf_r2_test, lr_r2_test) > 0.4:\n",
    "    print(\"   ‚ö†Ô∏è Modelo com capacidade preditiva moderada\")\n",
    "else:\n",
    "    print(\"   ‚ùå Modelo com baixa capacidade preditiva\")\n",
    "\n",
    "print(\"\\n‚úÖ Modelagem conclu√≠da com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
